import os
import base64
import json
from io import BytesIO
from typing import Dict, List, Optional, Tuple, Any
from groq import Groq
from PIL import Image
import torch
import numpy as np

from .utils.base_node import GroqNode, get_model_choices, ModelType

class GroqArtPromptGenerator(GroqNode):
    """GROQ Art Prompt Generator - Analyze images and create detailed art prompts for Stable Diffusion"""
    
    RETURN_TYPES = ("STRING", "BOOLEAN", "STRING")
    RETURN_NAMES = ("api_response", "success", "status_code")
    OUTPUT_TOOLTIPS = ("The API response. This is the description of your input image generated by the model", "Whether the request was successful", "The status code of the request")
    FUNCTION = "process_completion_request"
    CATEGORY = "GroqPrompt/Art Generation"
    OUTPUT_NODE = True
    
    @classmethod
    def INPUT_TYPES(cls):
        vision_models = get_model_choices(ModelType.VISION)
        
        return {
            "required": {
                "model": (vision_models, {
                    "default": "meta-llama/llama-4-maverick-17b-128e-instruct",
                    "tooltip": "Select the Vision-Language Model (VLM) to use."
                }),
                "system_message": ("STRING", {
                    "multiline": True, 
                    "default": "You are an expert art prompt engineer specializing in creating detailed prompts for AI art generation. Analyze images and create comprehensive Stable Diffusion prompts.",
                    "tooltip": "Optional system message to guide model behavior."
                }),
                "user_input": ("STRING", {
                    "multiline": True, 
                    "default": "Create a detailed art prompt for Stable Diffusion based on this image. Include style, lighting, composition, colors, and artistic techniques.",
                    "tooltip": "User input or prompt for the model to generate a response."
                }),
                "image": ("IMAGE", {
                    "label": "Image (required for VLM models)",
                    "tooltip": "Upload an image for processing by the VLM model."
                }),
                "temperature": ("FLOAT", {
                    "default": 0.85, 
                    "min": 0.1, 
                    "max": 2.0, 
                    "step": 0.05,
                    "tooltip": "Controls randomness in responses.\n\nA higher temperature makes the model take more risks, leading to more creative or varied answers.\n\nA lower temperature (closer to 0.1) makes the model more focused and predictable."
                }),
                "max_tokens": ("INT", {
                    "default": 1024, 
                    "min": 1, 
                    "max": 131072, 
                    "step": 1,
                    "tooltip": "Maximum number of tokens to generate in the output."
                }),
                "top_p": ("FLOAT", {
                    "default": 1.0, 
                    "min": 0.1, 
                    "max": 1.0, 
                    "step": 0.01,
                    "tooltip": "Limits the pool of words the model can choose from based on their combined probability.\n\nSet it closer to 1 to allow more variety in output. Lowering this (e.g., 0.9) will restrict the output to the most likely words, making responses more focused."
                }),
                "seed": ("INT", {
                    "default": 42, 
                    "min": 0, 
                    "max": 4294967295,
                    "tooltip": "Seed for random number generation, ensuring reproducibility."
                }),
                "max_retries": ("INT", {
                    "default": 2, 
                    "min": 1, 
                    "max": 10, 
                    "step": 1,
                    "tooltip": "Maximum number of retries in case of failures."
                }),
                "stop": ("STRING", {
                    "default": "",
                    "tooltip": "Stop generation when the specified sequence is encountered."
                }),
                "json_mode": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "Enable JSON mode for structured output.\n\nIMPORTANT: Requires you to use the word 'JSON' in the prompt."
                }),
            }
        }
    
    def process_completion_request(self, model, system_message, user_input, image, temperature, max_tokens, top_p, seed, max_retries, stop, json_mode, **kwargs):
        # Get API key from environment variable (matching original mnemic behavior)
        api_key = os.getenv('GROQ_API_KEY', '')
        if not api_key:
            return ("No API key found. Please set GROQ_API_KEY environment variable.", False, "401")
        
        # Set random seed if specified
        if seed != 42:
            import random
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
        
        # Initialize GROQ client
        client = Groq(api_key=api_key)
        
        # Process the image
        if isinstance(image, torch.Tensor):
            # Convert tensor to PIL Image
            if image.dim() == 4:  # Batch - take first image
                image = image[0]
            image_np = 255.0 * image.cpu().numpy()
            pil_image = Image.fromarray(np.clip(image_np, 0, 255).astype(np.uint8))
        else:
            pil_image = image
        
        # Convert to RGB if needed
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # Convert image to base64 for API
        buffered = BytesIO()
        pil_image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        
        # Prepare messages for API call
        messages = []
        
        # Add system message if provided
        if system_message.strip():
            messages.append({"role": "system", "content": system_message})
        
        # Add user input with image
        user_message = {
            "role": "user",
            "content": [
                {"type": "text", "text": user_input},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_base64}"
                    }
                }
            ]
        }
        messages.append(user_message)
        
        # Prepare request parameters
        request_params = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "top_p": top_p,
        }
        
        # Add stop sequence if provided
        if stop.strip():
            request_params["stop"] = [stop.strip()]
        
        # Add JSON mode if enabled
        if json_mode:
            request_params["response_format"] = {"type": "json_object"}
        
        # Make API call with retries
        for attempt in range(max_retries):
            try:
                response = client.chat.completions.create(**request_params)
                
                # Extract the response content
                if hasattr(response, 'choices') and len(response.choices) > 0:
                    content = response.choices[0].message.content
                    return (content, True, "200")
                
                return ("No response generated", False, "204")
                
            except Exception as e:
                if attempt < max_retries - 1:
                    continue
                return (f"Error after {max_retries} attempts: {str(e)}", False, "500")

# Node class mappings
NODE_CLASS_MAPPINGS = {
    "GroqArtPromptGenerator": GroqArtPromptGenerator,
}

# Node display names
NODE_DISPLAY_NAME_MAPPINGS = {
    "GroqArtPromptGenerator": "GROQ Art Prompt Generator",
}
